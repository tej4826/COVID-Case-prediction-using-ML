{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 8, 9, 10] (712, 11)\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "def import_data_and_weights(test_X_file_path, weights_file_path):\n",
    "    test_X = np.genfromtxt(test_X_file_path, delimiter=',', dtype=np.float64, skip_header=1)\n",
    "    weights = np.genfromtxt(weights_file_path, delimiter=',', dtype=np.float64)\n",
    "    return test_X, weights\n",
    "\n",
    "def sigmoid(Z):\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    return s\n",
    "\n",
    "def apply_one_hot_encoding(X):\n",
    "    unique_values = list(set(X))\n",
    "    unique_values.sort()\n",
    "    one_hot_encoding_map = {}\n",
    "    counter = 0\n",
    "    for x in unique_values:\n",
    "        one_hot_encoding_map[x] = [0 for i in range(len(unique_values))]\n",
    "        one_hot_encoding_map[x][counter] = 1\n",
    "        counter += 1\n",
    "    one_hot_encoded_X = []\n",
    "    for x in X:\n",
    "        one_hot_encoded_X.append(one_hot_encoding_map[x])\n",
    "\n",
    "    one_hot_encoded_X = np.array(one_hot_encoded_X, dtype=int)\n",
    "    return one_hot_encoded_X\n",
    "\n",
    "def convert_given_cols_to_one_hot(X, column_indices):\n",
    "    one_hot_encoded_X = np.zeros([len(X),1])\n",
    "\n",
    "    start_index = 0\n",
    "    #acts column pointer in X\n",
    "\n",
    "    for curr_index in column_indices:\n",
    "        #adding the columns present before curr_index in X (and not present in one_hot_encoded_X), to one_hot_encoded_X\n",
    "        one_hot_encoded_X=np.append(one_hot_encoded_X,X[:, start_index:curr_index], axis=1)\n",
    "        \n",
    "        #applying one hot encoding for current column\n",
    "        one_hot_encoded_column = apply_one_hot_encoding(X[:,curr_index])\n",
    "\n",
    "        #appending the obtained one hot encoded array to one_hot_encoded_X\n",
    "        one_hot_encoded_X=np.append(one_hot_encoded_X,one_hot_encoded_column, axis=1)\n",
    "\n",
    "        #moving the column pointer of X to next current_index\n",
    "        start_index = curr_index+1\n",
    "\n",
    "    #adding any remaining columns to one_hot_encoded_X    \n",
    "    one_hot_encoded_X=np.append(one_hot_encoded_X,X[:,start_index:], axis=1)\n",
    "    one_hot_encoded_X = one_hot_encoded_X[:,1:]\n",
    "    return one_hot_encoded_X\n",
    "\n",
    "def get_correlation_matrix(X):\n",
    "    num_vars = len(X[0])\n",
    "    m = len(X)\n",
    "    correlation_matix = np.zeros((num_vars,num_vars))\n",
    "    for i in range(0,num_vars):\n",
    "        for j in range(i,num_vars):\n",
    "            mean_i = np.mean(X[:,i])\n",
    "            mean_j = np.mean(X[:,j])\n",
    "            std_dev_i = np.std(X[:,i])\n",
    "            std_dev_j = np.std(X[:,j])\n",
    "            numerator = np.sum((X[:,i]-mean_i)*(X[:,j]-mean_j))\n",
    "            denominator = (m)*(std_dev_i)*(std_dev_j)\n",
    "            corr_i_j = numerator/denominator    \n",
    "            correlation_matix[i][j] = corr_i_j\n",
    "            correlation_matix[j][i] = corr_i_j\n",
    "    return correlation_matix\n",
    "\n",
    "def select_features(corr_mat, T1, T2):\n",
    "    n=len(corr_mat)\n",
    "    filtered_features = []\n",
    "    for i in range(1,n):\n",
    "        if (abs(corr_mat[i][0]) > T1):\n",
    "            filtered_features.append(i)\n",
    "    m = len(filtered_features)\n",
    "    removed_features = []\n",
    "    selected_features = list(filtered_features)\n",
    "    for i in range(0,m):\n",
    "        for j in range(i+1,m):\n",
    "            f1 = filtered_features[i]\n",
    "            f2 = filtered_features[j]\n",
    "            if (f1 not in removed_features and f2 not in removed_features): \n",
    "                if (abs(corr_mat[f1][f2]) > T2):\n",
    "                    selected_features.remove(f2)\n",
    "                    removed_features.append(f2)\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "def replace_null_values_with_mean(X):\n",
    "    #Obtain mean of columns\n",
    "    col_mean = np.nanmean(X, axis=0)\n",
    "\n",
    "    #Find indicies that we need to replace\n",
    "    inds = np.where(np.isnan(X))\n",
    "\n",
    "    #Place column means in the indices. Align the arrays using take\n",
    "    X[inds] = np.take(col_mean, inds[1])\n",
    "    return X\n",
    "\n",
    "def min_max_normalize(X, column_indices):\n",
    "    for column_index in column_indices:\n",
    "        column = X[:,column_index]\n",
    "        min = np.min(column, axis=0) \n",
    "        max = np.max(column, axis=0)\n",
    "        difference = max- min\n",
    "        X[:,column_index] = (column - min) /difference\n",
    "    return X\n",
    "\n",
    "def compute_cost(X, Y, W, b, Lambda):\n",
    "    Z = np.dot(X, W) + b\n",
    "    A = sigmoid(Z)\n",
    "    M=len(X)\n",
    "    A[A==1]=0.99999\n",
    "    A[A==0]=0.00001\n",
    "    cost = (-1/M) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A)) \n",
    "    regularization_cost = (Lambda * np.sum(np.square(W))) / (2 * M) \n",
    "    return cost + regularization_cost\n",
    "\n",
    "def compute_weights_using_normal_equation(X, Y, Lambda):\n",
    "    ones = np.ones(len(X))\n",
    "    X = np.insert(X, 0, ones, axis=1)\n",
    "    matrix = np.identity(len(X[0]))\n",
    "    matrix[0][0] = 0\n",
    "    regularization_term = Lambda * np.matrix(matrix)\n",
    "    weights = np.dot(np.linalg.inv(np.dot(X.T, X) + regularization_term), np.dot(X.T, Y))\n",
    "    return weights\n",
    "\n",
    "def compute_gradients_using_regularization(X, Y, W, b, Lambda):\n",
    "    m = len(X)\n",
    "    A = np.dot(X, W) + b\n",
    "    dW = 1/m * (np.dot((A-Y).T, X) + Lambda*(W.T))\n",
    "    db = 1/m * np.sum(A-Y)\n",
    "    dW = dW.T\n",
    "    return dW, db\n",
    "\n",
    "def predict_labels(X, W, b):\n",
    "    A = sigmoid(np.dot(X,W) + b)\n",
    "    A = A.T[0]\n",
    "    Y_prediction = np.where(A >= 0.5, 1, 0)\n",
    "    return Y_prediction\n",
    "def train_data_for_class(train_X,train_Y,class_label):\n",
    "    class_X=np.copy(train_X)\n",
    "    class_Y=np.copy(train_Y)\n",
    "    class_Y=np.where(class_Y==class_label,1,0)\n",
    "    return class_X, class_Y\n",
    "def optimize_weights_using_gradient_descent(X, Y, W, learning_rate , precision,Lambda):\n",
    "    prev_itr_cost=0\n",
    "    itr=0\n",
    "    b=0\n",
    "    #print(\"W=\",W)\n",
    "    while(1):\n",
    "        itr+=1\n",
    "        dW,db = compute_gradients_using_regularization(X, Y, W, b,Lambda)\n",
    "        #print(\"dw=\",dW)\n",
    "        W = W - (learning_rate * dW)\n",
    "        b = b - (learning_rate * db)\n",
    "        #print(\"W=new\",W)\n",
    "        cost=compute_cost(X, Y, W, b,Lambda)\n",
    "        if(itr%10000==0):\n",
    "            print(\"cost=\",cost,itr)\n",
    "        if abs(prev_itr_cost-cost)<precision:\n",
    "            print(itr,cost)\n",
    "            break\n",
    "        prev_itr_cost=cost\n",
    "        #print(i,\" \",cost)\n",
    "    return (W,b)\n",
    "def train_model(X,Y,learning_rate , precision,Lambda):\n",
    "    Y=Y.reshape(len(X),1)\n",
    "    W=np.zeros((X.shape[1],1))\n",
    "    W,b=optimize_weights_using_gradient_descent(X, Y, W, learning_rate, precision,Lambda)\n",
    "    W = np.append(W,b)\n",
    "    #print(W)\n",
    "    return W\n",
    "def save_model(weights,weights_filename):\n",
    "    with open(weights_filename,'w') as weights_file:\n",
    "        wr=csv.writer(weights_file)\n",
    "        wr.writerows(weights)\n",
    "        weights_file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    test1,test2=import_data_and_weights(\"train_X_pr.csv\",\"train_Y_pr.csv\")\n",
    "    X,Y = test1,test2\n",
    "    weights_array = []\n",
    "    X,Y = train_data_for_class(test1,test2,0)\n",
    "    X = replace_null_values_with_mean(X)\n",
    "    X = convert_given_cols_to_one_hot(X, [0,3])\n",
    "    m=(X.shape)[0]\n",
    "    n=(X.shape)[1]\n",
    "    col=[]\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if X[j][i]>1 or X[j][i]<0:\n",
    "                col.append(i)\n",
    "                break\n",
    "    X = min_max_normalize(X, col)\n",
    "    corr_mat = get_correlation_matrix(X)\n",
    "    fea = select_features(corr_mat, 0, 0.7)\n",
    "    print(fea,X.shape)\n",
    "    count=0\n",
    "    for i in range(n):\n",
    "        if i not in fea:\n",
    "            X=np.delete(X,i-count,axis=1)\n",
    "            count+=1\n",
    "    #print(X[:20])\n",
    "    weights = compute_weights_using_normal_equation(X, Y, 0.1)\n",
    "    weights=weights.T\n",
    "    a,b=weights.shape\n",
    "    c=np.zeros(a)\n",
    "    for i in range(a):\n",
    "        c[i] = weights[i]\n",
    "    weights=c\n",
    "    \n",
    "    \n",
    "    #weights=train_model(X,Y,0.007,0.00000001,0.1)\n",
    "    weights_array.append(weights)\n",
    "    \n",
    "    X,Y = train_data_for_class(test1,test2,1)\n",
    "    X = replace_null_values_with_mean(X)\n",
    "    X = convert_given_cols_to_one_hot(X, [0,3])\n",
    "    m=(X.shape)[0]\n",
    "    n=(X.shape)[1]\n",
    "    col=[]\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if X[j][i]>1 or X[j][i]<0:\n",
    "                col.append(i)\n",
    "                break\n",
    "    X = min_max_normalize(X, col)\n",
    "    corr_mat = get_correlation_matrix(X)\n",
    "    fea = select_features(corr_mat, 0, 0.7)\n",
    "    print(fea)\n",
    "    count=0\n",
    "    for i in range(n):\n",
    "        if i not in fea:\n",
    "            X=np.delete(X,i-count,axis=1)\n",
    "            count+=1\n",
    "    #print(X[:20])\n",
    "    weights = compute_weights_using_normal_equation(X, Y, 0.1)\n",
    "    weights=weights.T\n",
    "    a,b=weights.shape\n",
    "    c=np.zeros(a)\n",
    "    for i in range(a):\n",
    "        c[i] = weights[i]\n",
    "    weights=c\n",
    "    \n",
    "    #weights=train_model(X,Y,0.007,0.00000001,0.1)\n",
    "    weights_array.append(weights)\n",
    "#     weights=weights.T\n",
    "#     a,b=weights.shape\n",
    "#     c=np.zeros(a)\n",
    "#     for i in range(a):\n",
    "#         c[i] = weights[i]\n",
    "#     weights=c\n",
    "    #print(weights,X.shape)\n",
    "    #print(weights,c)\n",
    "    save_model(weights_array,\"WEIGHTS_FILE.csv\")\n",
    "    #save_model(weights,\"WEIGHTS_FILE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
